{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f171042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- 1. FORMATTING & HEADING LOGIC ---\n",
    "\n",
    "def is_bold(font_name):\n",
    "    \"\"\"Checks if the font name contains keywords suggesting 'Bold'.\"\"\"\n",
    "    return 'bold' in font_name.lower() or 'black' in font_name.lower()\n",
    "\n",
    "def is_italic(font_name):\n",
    "    \"\"\"Checks if the font name contains keywords suggesting 'Italic'.\"\"\"\n",
    "    return 'italic' in font_name.lower() or 'oblique' in font_name.lower()\n",
    "\n",
    "def get_word_format_type(font_name):\n",
    "    \"\"\"Determines the format type: 'bold', 'italic', or 'none'.\"\"\"\n",
    "    if is_bold(font_name):\n",
    "        return 'bold'\n",
    "    if is_italic(font_name):\n",
    "        return 'italic'\n",
    "    return 'none'\n",
    "\n",
    "def dataframe_to_custom_html(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Converts a Pandas DataFrame into a highly customized HTML table structure\n",
    "    where every cell is wrapped in <blockquote><p> tags and headers are bolded.\n",
    "    \"\"\"\n",
    "    html_parts = []\n",
    "    \n",
    "    # Start Table\n",
    "    html_parts.append(\"<table>\")\n",
    "\n",
    "    # 1. Generate Colgroup (one <col/> for each column)\n",
    "    html_parts.append(\"<colgroup>\")\n",
    "    for _ in df.columns:\n",
    "        html_parts.append(\"<col/>\")\n",
    "    html_parts.append(\"</colgroup>\")\n",
    "\n",
    "    # 2. Generate Table Header (<thead>)\n",
    "    html_parts.append(\"<thead>\")\n",
    "    html_parts.append(\"<tr>\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Header cell requires <blockquote><p><strong>...</strong></p></blockquote>\n",
    "        header_content = f\"<blockquote><p><strong>{col}</strong></p></blockquote>\"\n",
    "        html_parts.append(f\"<th>{header_content}</th>\")\n",
    "        \n",
    "    html_parts.append(\"</tr>\")\n",
    "    html_parts.append(\"</thead>\")\n",
    "\n",
    "    # 3. Generate Table Body (<tbody>)\n",
    "    html_parts.append(\"<tbody>\")\n",
    "    \n",
    "    # Iterate through rows\n",
    "    for _, row in df.iterrows():\n",
    "        html_parts.append(\"<tr>\")\n",
    "        \n",
    "        # Iterate through cells in the row\n",
    "        for cell_value in row:\n",
    "            # Data cell requires <blockquote><p>...</p></blockquote>\n",
    "            # Convert cell value to string to handle mixed types\n",
    "            cell_str = str(cell_value)\n",
    "            data_content = f\"<blockquote><p>{cell_str}</p></blockquote>\"\n",
    "            html_parts.append(f\"<td>{data_content}</td>\")\n",
    "            \n",
    "        html_parts.append(\"</tr>\")\n",
    "        \n",
    "    html_parts.append(\"</tbody>\")\n",
    "    \n",
    "    # End Table\n",
    "    html_parts.append(\"</table>\")\n",
    "    \n",
    "    return \"\\n\".join(html_parts)\n",
    "\n",
    "def process_block(block):\n",
    "    \"\"\"\n",
    "    Wraps a text block with appropriate Markdown syntax.\n",
    "    \n",
    "    If the block is bold and starts with a numbered list (e.g., \"1. \"), \n",
    "    it is treated as a special [DIGITAL] heading, and the numbering is removed.\n",
    "    \"\"\"\n",
    "    # Join words into a single string\n",
    "    text = \" \".join(block['words'])\n",
    "    \n",
    "    # Regex pattern: start of string (^), one or more digits (\\d+), dot (\\.), space (\\s)\n",
    "    ordered_list_pattern = re.compile(r\"^\\d+\\.\\s\")\n",
    "    ordered_sublist_pattern = re.compile(r\"^\\d+\\.\\d+\")\n",
    "    ordered_subsublist_pattern = re.compile(r\"^\\d+\\.\\d+\\.\\d+\")\n",
    "\n",
    "\n",
    "    \n",
    "    # 1. Check for [DIGITAL] Heading (Highest Priority)\n",
    "    if block['type'] == 'bold' and ordered_subsublist_pattern.match(text):\n",
    "        return \"### \" + text\n",
    "    if block['type'] == 'bold' and ordered_sublist_pattern.match(text):\n",
    "        # Remove the numbering part (e.g., \"1.1. \")\n",
    "        # cleaned_text = re.sub(ordered_sublist_pattern, \"## \", text, count=1)\n",
    "        # Apply the [DIGITAL] prefix\n",
    "        return \"## \"+ text\n",
    "    elif block['type'] == 'bold' and ordered_list_pattern.match(text):\n",
    "        # Remove the numbering part (e.g., \"1. \")\n",
    "        # cleaned_text = re.sub(ordered_list_pattern, \"# \", text, count=1)\n",
    "        # Apply the [DIGITAL] prefix\n",
    "        return \"# \" + text\n",
    "        \n",
    "    # 2. Regular Bold Formatting\n",
    "    elif block['type'] == 'bold':\n",
    "        return f\"**{text}** \"\n",
    "        \n",
    "    # 3. Italic Formatting\n",
    "    elif block['type'] == 'italic':\n",
    "        return f\"*{text}* \"\n",
    "        \n",
    "    # 4. No Formatting\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# --- 2. TABLE PROCESSING LOGIC ---\n",
    "\n",
    "def pdfplumber_table_to_markdown(table):\n",
    "    \"\"\"Converts a pdfplumber Table object to a Markdown string.\"\"\"\n",
    "    \n",
    "    data = table.extract()\n",
    "    if not data or not data[0]:\n",
    "        return \"\"\n",
    "    \n",
    "    # Use Pandas for clean conversion to Markdown table syntax\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    # Fill None/NaN with empty strings for clean Markdown rendering\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('') \n",
    "\n",
    "    if len(df) > 1:\n",
    "        header = df.iloc[0].astype(str).fillna('')\n",
    "        df_no_header = df[1:].copy().reset_index(drop=True)\n",
    "        df_no_header.columns = header\n",
    "    else:\n",
    "        # Nếu chỉ có một hàng (chỉ header), tạo DataFrame rỗng với header đó\n",
    "        header = df.iloc[0].astype(str).fillna('') if len(df) == 1 else []\n",
    "        df_no_header = pd.DataFrame(columns=header)\n",
    "    html_table = dataframe_to_custom_html(df_no_header)\n",
    "    # markdown_output = df_no_header.to_markdown(index=False)\n",
    "    # Add extra lines for separation\n",
    "    return \"\\n\" + html_table + \"\\n\\n\"\n",
    "\n",
    "# --- 3. CORE STITCHING LOGIC ---\n",
    "\n",
    "def get_block_type_and_filter(line, table_bboxes):\n",
    "    \"\"\"\n",
    "    Checks if a text line overlaps with any table bbox. \n",
    "    Returns the line object if it's external text, otherwise returns None (filtered out).\n",
    "    \"\"\"\n",
    "    # Get Y coordinates of the text line\n",
    "    line_y_top = line['top']\n",
    "    line_y_bottom = line['bottom']\n",
    "    \n",
    "    for t_x0, t_top, t_x1, t_bottom in table_bboxes:\n",
    "        # Check for overlap in the Y-axis\n",
    "        # If the line is fully contained within the table's Y range, filter it out.\n",
    "        if t_top <= line_y_top < t_bottom and t_top < line_y_bottom <= t_bottom:\n",
    "             return None # It's part of a table, discard the text line\n",
    "    \n",
    "    # If it passed the filter, return the line object\n",
    "    return line\n",
    "\n",
    "def merge_formatted_blocks(page_id, formatted_words):\n",
    "    \"\"\"\n",
    "    Merges consecutive words with the same formatting into a list of structured \n",
    "    content blocks, suitable for positional stitching.\n",
    "    \"\"\"\n",
    "    if not formatted_words:\n",
    "        return []\n",
    "    \n",
    "    # This list will hold the final dictionary blocks\n",
    "    result_blocks = []\n",
    "    current_block = None\n",
    "    block_start_top = None # To track the 'top' coordinate of the starting word\n",
    "    \n",
    "    # Ensure words are sorted by position before merging (Top then X-axis)\n",
    "    # The calling function (pdf_to_markdown_pipeline) usually does this, \n",
    "    # but it's good practice to ensure here as well.\n",
    "    new_words = []\n",
    "    for word in formatted_words:\n",
    "        if word['text'] == \"\\n\":\n",
    "            continue\n",
    "        new_words.append(word)\n",
    "    formatted_words = new_words\n",
    "    formatted_words.sort(key=lambda w: (w['top'], w['x0']))\n",
    "\n",
    "\n",
    "\n",
    "    list_words = [w['text'] for w in formatted_words]\n",
    "    # if page_id == 4:\n",
    "    #     import ipdb; ipdb.set_trace()\n",
    "    for i, word in enumerate(formatted_words):\n",
    "        # Check if this word is on the same line as the previous word (Y coordinate check)\n",
    "        is_same_line = False\n",
    "        \n",
    "        if i > 0:\n",
    "            if abs(word['top'] - formatted_words[i-1]['top']) < 7:\n",
    "                is_same_line = True\n",
    "            elif formatted_words[i-1]['x1'] > 507 and not word['text'][0].isupper():\n",
    "                # Special case: if previous word is at the far right and current word starts with lowercase,\n",
    "                # consider it as same line (likely a line continuation)\n",
    "                is_same_line = True\n",
    "                # if page_id == 2:\n",
    "                    # print(\"Special line continuation detected:\", formatted_words[i-1]['text'], \"->\", word['text'])\n",
    "                    # print(formatted_words[i-1], word, formatted_words[i+1])\n",
    "        \n",
    "                \n",
    "        if current_block is None:\n",
    "            # Start the very first block\n",
    "            current_block = {'type': word['type'], 'words': [word['text']]}\n",
    "            block_start_top = word['top'] # Capture starting position\n",
    "            continue\n",
    "        \n",
    "        # If line break detected OR format changes:\n",
    "        if not is_same_line or word['type'] != current_block['type']:\n",
    "            \n",
    "            # --- END OF CURRENT BLOCK ---\n",
    "            # 1. Process the finished block and append to results list\n",
    "            # We use the captured 'top' coordinate of the *starting* word\n",
    "            result_blocks.append({\n",
    "                'type': 'text',\n",
    "                'top': block_start_top,\n",
    "                'content': process_block(current_block)\n",
    "            })\n",
    "            \n",
    "            # --- START OF NEW BLOCK ---\n",
    "            # 2. Initialize the new block with the current word\n",
    "            current_block = {'type': word['type'], 'words': [word['text']]}\n",
    "            block_start_top = word['top'] # Capture starting position of the new block\n",
    "        \n",
    "        else:\n",
    "            current_block['words'].append(word['text'])\n",
    "            # Same line and same format, append word to current block\n",
    "            # Ensure we maintain x0 positions for sorting when inserting new words\n",
    "            # Initialize parallel _x0s list if not present (attempt to recover x0 for existing words)\n",
    "            # if '_x0s' not in current_block:\n",
    "            #     existing_x0s = []\n",
    "            #     for existing_text in current_block['words']:\n",
    "            #         found_x0 = None\n",
    "            #         # try to find a matching formatted word on the same line to get its x0\n",
    "            #         for fw in formatted_words:\n",
    "            #             if fw['text'] == existing_text and abs(fw['top'] - block_start_top) < 8:\n",
    "            #                 found_x0 = fw.get('x0', 0)\n",
    "            #                 break\n",
    "            #         existing_x0s.append(found_x0 if found_x0 is not None else 0)\n",
    "            #     current_block['_x0s'] = existing_x0s\n",
    "\n",
    "            # # Find insertion index based on word['x0']\n",
    "            # insert_idx = len(current_block['words'])\n",
    "            # for idx, existing_x0 in enumerate(current_block['_x0s']):\n",
    "            #     if word['x0'] < existing_x0:\n",
    "            #         insert_idx = idx\n",
    "            #         break\n",
    "\n",
    "            # Insert text and corresponding x0 at the computed position\n",
    "            # current_block['words'].insert(insert_idx, word['text'])\n",
    "            # current_block['_x0s'].insert(insert_idx, word['x0'])\n",
    "    \n",
    "    # Process the very last block after the loop ends\n",
    "    if current_block:\n",
    "        result_blocks.append({\n",
    "            'type': 'text',\n",
    "            'top': block_start_top,\n",
    "            'content': process_block(current_block)\n",
    "        })\n",
    "        \n",
    "    return result_blocks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44905ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./sample/gt/Public_017.pdf with 10 pages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Conversion successful! Output saved at: ./sample/pred/Public_017.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1195022/3406378661.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUTION ---\n",
    "pdf_path = \"./sample/gt/Public_017.pdf\" \n",
    "output_path = pdf_path.replace('.pdf', '.md').replace(\"gt\",\"pred\")\n",
    "\n",
    "markdown_content = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    print(f\"Processing file: {pdf_path} with {len(pdf.pages)} pages...\")\n",
    "    \n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        \n",
    "        # --- Step 1: Extract Tables and Text Lines ---\n",
    "        tables = page.find_tables()\n",
    "        table_bboxes = [t.bbox for t in tables]\n",
    "        \n",
    "        text_lines = page.extract_text_lines(T_y_tolerance=3)\n",
    "        \n",
    "        # --- Step 2: Filter Text and Prepare Content Blocks ---\n",
    "        \n",
    "        # List to hold all content objects (Text or Table) with their position\n",
    "        content_blocks = []\n",
    "        \n",
    "        # a. Prepare Table Blocks\n",
    "        for table in tables:\n",
    "            content_blocks.append({\n",
    "                'type': 'table',\n",
    "                'top': table.bbox[1], \n",
    "                'content': pdfplumber_table_to_markdown(table)\n",
    "            })\n",
    "\n",
    "        # b. Filter and Group Text Lines\n",
    "        # The text processing is complex:\n",
    "        # 1. We must process 'words' to get formatting information.\n",
    "        # 2. We must use 'text_lines' to get accurate positioning for filtering.\n",
    "        \n",
    "        # Extract all formatted words on the page\n",
    "        all_formatted_words = []\n",
    "        words = page.extract_words()\n",
    "        chars = page.chars\n",
    "        \n",
    "        for word in words:\n",
    "            # Get font name (assume one font per word)\n",
    "            word_chars = [c for c in chars if c['x0'] >= word['x0'] and c['x1'] <= word['x1'] and c['top'] >= word['top'] and c['bottom'] <= word['bottom']]\n",
    "            \n",
    "            font_name = word_chars[0]['fontname'] if word_chars else 'none'\n",
    "            \n",
    "            # Store as a list of word objects\n",
    "            all_formatted_words.append({\n",
    "                'text': word['text'],\n",
    "                'type': get_word_format_type(font_name),\n",
    "                'top': word['top'], \n",
    "                'bottom': word['bottom'],\n",
    "                'x0': word['x0'],\n",
    "                'x1': word['x1']\n",
    "            })\n",
    "\n",
    "        # c. Group and Filter Formatted Words into Text Blocks\n",
    "        text_blocks_to_merge = []\n",
    "        \n",
    "        # Group words into lines based on Y coordinate\n",
    "        current_line_words = []\n",
    "        last_bottom = 0\n",
    "        \n",
    "        # Sort words primarily by 'top' (Y-axis) and secondarily by 'x0' (X-axis)\n",
    "        all_formatted_words.sort(key=lambda w: (w['top'], w['x0']))\n",
    "        \n",
    "        for word in all_formatted_words:\n",
    "            # Check for line break (if current word's top is significantly different from the last word's bottom)\n",
    "            if current_line_words and (word['top'] > last_bottom + 7): \n",
    "                # Process the previous line\n",
    "                if not current_line_words: continue\n",
    "\n",
    "                # Check if this line overlaps with any table (using the whole line's bbox)\n",
    "                line_top = min(w['top'] for w in current_line_words)\n",
    "                line_bottom = max(w['bottom'] for w in current_line_words)\n",
    "                line_x0 = min(w['x0'] for w in current_line_words)\n",
    "                line_x1 = max(w['x1'] for w in current_line_words)\n",
    "                \n",
    "                line_bbox = (line_x0, line_top, line_x1, line_bottom)\n",
    "                \n",
    "                # Apply table filtering logic\n",
    "                is_external_text = get_block_type_and_filter({'top': line_top, 'bottom': line_bottom}, table_bboxes)\n",
    "\n",
    "                if is_external_text is not None:\n",
    "                    text_blocks_to_merge.extend(current_line_words)\n",
    "                    text_blocks_to_merge.append({'text': '\\n', 'type': 'line_break', 'top': line_bottom, 'bottom': line_bottom, 'x0': 0, 'x1': 0})\n",
    "\n",
    "                current_line_words = []\n",
    "            \n",
    "            current_line_words.append(word)\n",
    "            last_bottom = word['bottom']\n",
    "\n",
    "        # Process the last line\n",
    "        if current_line_words:\n",
    "            line_top = min(w['top'] for w in current_line_words)\n",
    "            line_bottom = max(w['bottom'] for w in current_line_words)\n",
    "            \n",
    "            is_external_text = get_block_type_and_filter({'top': line_top, 'bottom': line_bottom}, table_bboxes)\n",
    "\n",
    "            if is_external_text is not None:\n",
    "                text_blocks_to_merge.extend(current_line_words)\n",
    "        \n",
    "        # 4. Merge Formatted Blocks and Prepare for Stitching\n",
    "        # The merge_formatted_blocks function implicitly handles line breaks and formatting\n",
    "        text_blocks = merge_formatted_blocks(i, text_blocks_to_merge)\n",
    "        content_blocks.extend(text_blocks)\n",
    "    \n",
    "\n",
    "        # --- Step 5: Stitch Content Blocks by Position ---\n",
    "        \n",
    "        # Sort all content (Text and Table) based on 'top' coordinate (Y-axis)\n",
    "        content_blocks.sort(key=lambda x: x['top'])\n",
    "        if content_blocks[0]['type'] == 'table' and \"VIETTEL AI RACE\" in content_blocks[0]['content']:\n",
    "            content_blocks = content_blocks[1:]\n",
    "        # if i==4:\n",
    "        #     import ipdb; ipdb.set_trace()   \n",
    "        # Append to final output\n",
    "        page_markdown = [block['content'] for block in content_blocks]\n",
    "        \n",
    "        # markdown_content.append(f\"## Page {i + 1}\\n\")\n",
    "        markdown_content.extend(page_markdown)\n",
    "        # if i == 2:\n",
    "        #     break\n",
    "markdown_content = \"\\n\".join(markdown_content)\n",
    "filename = pdf_path.split('/')[-1].split('.pdf')[0]\n",
    "markdown_content = \"# \" + filename+\"\\n\\n\" + markdown_content\n",
    "markdown_content = markdown_content.replace(\"foo\", \"\")\n",
    "\n",
    "# markdown_content = re.sub(r'\\s\\n.', ' ', markdown_content)\n",
    "# markdown_content = markdown_content.replace(' \\n', ' ')\n",
    "# Write result to file\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(markdown_content)\n",
    "    \n",
    "print(f\"\\n✅ Conversion successful! Output saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f729bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final averaged results: {'text_eds': 0.7701726117798158, 'text_f1': 0.7656608195896699, 'head_eds': 0.48155058043117743, 'head_teds': 0.3996511406247711, 'seg_kt': np.float64(0.9918885558102628), 'word_kt': np.float64(0.9873623496254981), 'seg_sp': np.float64(0.993426595348655), 'word_sp': np.float64(0.9841185462454102)}\n",
      "top 5 lowest edit distance scores:\n",
      "Public_257.md: 0.5785045950523364\n",
      "Public_017.md: 0.9618406285072951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! python3 evaluation/suite_e2e.py --gold_dir sample/gt --pred_dir sample/pred/ --result_json sample/gt.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
