{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23981ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 958 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pdfminer.six==20251107\n",
      "  Downloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /Users/qcuong/Downloads/var_2025_task2/var/lib/python3.9/site-packages (from pdfplumber) (11.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /Users/qcuong/Downloads/var_2025_task2/var/lib/python3.9/site-packages (from pdfplumber) (5.1.0)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Downloading cryptography-46.0.3-cp38-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 471 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /Users/qcuong/Downloads/var_2025_task2/var/lib/python3.9/site-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: typing-extensions>=4.13.2 in /Users/qcuong/Downloads/var_2025_task2/var/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (4.15.0)\n",
      "Collecting cffi>=2.0.0\n",
      "  Downloading cffi-2.0.0-cp39-cp39-macosx_11_0_arm64.whl (180 kB)\n",
      "\u001b[K     |████████████████████████████████| 180 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed cffi-2.0.0 cryptography-46.0.3 pdfminer.six-20251107 pdfplumber-0.11.8 pycparser-2.23\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Users/qcuong/Downloads/var_2025_task2/var/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f171042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- 1. FORMATTING & HEADING LOGIC ---\n",
    "\n",
    "def is_bold(font_name):\n",
    "    \"\"\"Checks if the font name contains keywords suggesting 'Bold'.\"\"\"\n",
    "    return 'bold' in font_name.lower() or 'black' in font_name.lower()\n",
    "\n",
    "def is_italic(font_name):\n",
    "    \"\"\"Checks if the font name contains keywords suggesting 'Italic'.\"\"\"\n",
    "    return 'italic' in font_name.lower() or 'oblique' in font_name.lower()\n",
    "\n",
    "def get_word_format_type(font_name):\n",
    "    \"\"\"Determines the format type: 'bold', 'italic', or 'none'.\"\"\"\n",
    "    if is_bold(font_name):\n",
    "        return 'bold'\n",
    "    if is_italic(font_name):\n",
    "        return 'italic'\n",
    "    return 'none'\n",
    "\n",
    "def dataframe_to_custom_html(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Converts a Pandas DataFrame into a highly customized HTML table structure\n",
    "    where every cell is wrapped in <blockquote><p> tags and headers are bolded.\n",
    "    \"\"\"\n",
    "    html_parts = []\n",
    "    \n",
    "    # Start Table\n",
    "    html_parts.append(\"<table>\")\n",
    "\n",
    "    # 1. Generate Colgroup (one <col/> for each column)\n",
    "    html_parts.append(\"<colgroup>\")\n",
    "    for _ in df.columns:\n",
    "        html_parts.append(\"<col/>\")\n",
    "    html_parts.append(\"</colgroup>\")\n",
    "\n",
    "    # 2. Generate Table Header (<thead>)\n",
    "    html_parts.append(\"<thead>\")\n",
    "    html_parts.append(\"<tr>\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Header cell requires <blockquote><p><strong>...</strong></p></blockquote>\n",
    "        header_content = f\"<blockquote><p><strong>{col}</strong></p></blockquote>\"\n",
    "        html_parts.append(f\"<th>{header_content}</th>\")\n",
    "        \n",
    "    html_parts.append(\"</tr>\")\n",
    "    html_parts.append(\"</thead>\")\n",
    "\n",
    "    # 3. Generate Table Body (<tbody>)\n",
    "    html_parts.append(\"<tbody>\")\n",
    "    \n",
    "    # Iterate through rows\n",
    "    for _, row in df.iterrows():\n",
    "        html_parts.append(\"<tr>\")\n",
    "        \n",
    "        # Iterate through cells in the row\n",
    "        for cell_value in row:\n",
    "            # Data cell requires <blockquote><p>...</p></blockquote>\n",
    "            # Convert cell value to string to handle mixed types\n",
    "            cell_str = str(cell_value)\n",
    "            data_content = f\"<blockquote><p>{cell_str}</p></blockquote>\"\n",
    "            html_parts.append(f\"<td>{data_content}</td>\")\n",
    "            \n",
    "        html_parts.append(\"</tr>\")\n",
    "        \n",
    "    html_parts.append(\"</tbody>\")\n",
    "    \n",
    "    # End Table\n",
    "    html_parts.append(\"</table>\")\n",
    "    \n",
    "    return \"\\n\".join(html_parts)\n",
    "\n",
    "def process_block(block):\n",
    "    \"\"\"\n",
    "    Wraps a text block with appropriate Markdown syntax.\n",
    "    \n",
    "    If the block is bold and starts with a numbered list (e.g., \"1. \"), \n",
    "    it is treated as a special [DIGITAL] heading, and the numbering is removed.\n",
    "    \"\"\"\n",
    "    # Join words into a single string\n",
    "    text = \" \".join(block['words'])\n",
    "    \n",
    "    # Regex pattern: start of string (^), one or more digits (\\d+), dot (\\.), space (\\s)\n",
    "    ordered_list_pattern = re.compile(r\"^\\d+\\.\\s\")\n",
    "    ordered_sublist_pattern = re.compile(r\"^\\d+\\.\\d+\")\n",
    "    ordered_subsublist_pattern = re.compile(r\"^\\d+\\.\\d+\\.\\d+\")\n",
    "\n",
    "\n",
    "    \n",
    "    # 1. Check for [DIGITAL] Heading (Highest Priority)\n",
    "    if block['type'] == 'bold' and ordered_subsublist_pattern.match(text):\n",
    "        return \"### \" + text\n",
    "    if block['type'] == 'bold' and ordered_sublist_pattern.match(text):\n",
    "        # Remove the numbering part (e.g., \"1.1. \")\n",
    "        # cleaned_text = re.sub(ordered_sublist_pattern, \"## \", text, count=1)\n",
    "        # Apply the [DIGITAL] prefix\n",
    "        return \"## \"+ text\n",
    "    elif block['type'] == 'bold' and ordered_list_pattern.match(text):\n",
    "        # Remove the numbering part (e.g., \"1. \")\n",
    "        # cleaned_text = re.sub(ordered_list_pattern, \"# \", text, count=1)\n",
    "        # Apply the [DIGITAL] prefix\n",
    "        return \"# \" + text\n",
    "        \n",
    "    # 2. Regular Bold Formatting\n",
    "    elif block['type'] == 'bold':\n",
    "        return f\"**{text}** \"\n",
    "        \n",
    "    # 3. Italic Formatting\n",
    "    elif block['type'] == 'italic':\n",
    "        return f\"_{text}_ \"\n",
    "        \n",
    "    # 4. No Formatting\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# --- 2. TABLE PROCESSING LOGIC ---\n",
    "\n",
    "def pdfplumber_table_to_markdown(table):\n",
    "    \"\"\"Converts a pdfplumber Table object to a Markdown string.\"\"\"\n",
    "    \n",
    "    data = table.extract()\n",
    "    if not data or not data[0]:\n",
    "        return \"\"\n",
    "    \n",
    "    # Use Pandas for clean conversion to Markdown table syntax\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    # Fill None/NaN with empty strings for clean Markdown rendering\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('') \n",
    "\n",
    "    if len(df) > 1:\n",
    "        header = df.iloc[0].astype(str).fillna('')\n",
    "        df_no_header = df[1:].copy().reset_index(drop=True)\n",
    "        df_no_header.columns = header\n",
    "    else:\n",
    "        # Nếu chỉ có một hàng (chỉ header), tạo DataFrame rỗng với header đó\n",
    "        header = df.iloc[0].astype(str).fillna('') if len(df) == 1 else []\n",
    "        df_no_header = pd.DataFrame(columns=header)\n",
    "    html_table = dataframe_to_custom_html(df_no_header)\n",
    "    # markdown_output = df_no_header.to_markdown(index=False)\n",
    "    # Add extra lines for separation\n",
    "    return \"\\n\" + html_table + \"\\n\\n\"\n",
    "\n",
    "# --- 3. CORE STITCHING LOGIC ---\n",
    "\n",
    "def get_block_type_and_filter(line, table_bboxes):\n",
    "    \"\"\"\n",
    "    Checks if a text line overlaps with any table bbox. \n",
    "    Returns the line object if it's external text, otherwise returns None (filtered out).\n",
    "    \"\"\"\n",
    "    # Get Y coordinates of the text line\n",
    "    line_y_top = line['top']\n",
    "    line_y_bottom = line['bottom']\n",
    "    \n",
    "    for t_x0, t_top, t_x1, t_bottom in table_bboxes:\n",
    "        # Check for overlap in the Y-axis\n",
    "        # If the line is fully contained within the table's Y range, filter it out.\n",
    "        if t_top <= line_y_top < t_bottom and t_top < line_y_bottom <= t_bottom:\n",
    "             return None # It's part of a table, discard the text line\n",
    "    \n",
    "    # If it passed the filter, return the line object\n",
    "    return line\n",
    "\n",
    "def merge_formatted_blocks(page_id, formatted_words):\n",
    "    \"\"\"\n",
    "    Merges consecutive words with the same formatting into a list of structured \n",
    "    content blocks, suitable for positional stitching.\n",
    "    \"\"\"\n",
    "    if not formatted_words:\n",
    "        return []\n",
    "    \n",
    "    # This list will hold the final dictionary blocks\n",
    "    result_blocks = []\n",
    "    current_block = None\n",
    "    block_start_top = None # To track the 'top' coordinate of the starting word\n",
    "    \n",
    "    # Ensure words are sorted by position before merging (Top then X-axis)\n",
    "    # The calling function (pdf_to_markdown_pipeline) usually does this, \n",
    "    # but it's good practice to ensure here as well.\n",
    "    new_words = []\n",
    "    for word in formatted_words:\n",
    "        if word['text'] == \"\\n\":\n",
    "            continue\n",
    "        new_words.append(word)\n",
    "    formatted_words = new_words\n",
    "    formatted_words.sort(key=lambda w: (w['top'], w['x0']))\n",
    "\n",
    "\n",
    "\n",
    "    list_words = [w['text'] for w in formatted_words]\n",
    "    # if page_id == 4:\n",
    "    #     import ipdb; ipdb.set_trace()\n",
    "    for i, word in enumerate(formatted_words):\n",
    "        # Check if this word is on the same line as the previous word (Y coordinate check)\n",
    "        is_same_line = False\n",
    "        \n",
    "        if i > 0:\n",
    "            if abs(word['top'] - formatted_words[i-1]['top']) < 7:\n",
    "                is_same_line = True\n",
    "            elif formatted_words[i-1]['x1'] > 507 and not word['text'][0].isupper():\n",
    "                # Special case: if previous word is at the far right and current word starts with lowercase,\n",
    "                # consider it as same line (likely a line continuation)\n",
    "                is_same_line = True\n",
    "                # if page_id == 2:\n",
    "                    # print(\"Special line continuation detected:\", formatted_words[i-1]['text'], \"->\", word['text'])\n",
    "                    # print(formatted_words[i-1], word, formatted_words[i+1])\n",
    "        \n",
    "                \n",
    "        if current_block is None:\n",
    "            # Start the very first block\n",
    "            current_block = {'type': word['type'], 'words': [word['text']]}\n",
    "            block_start_top = word['top'] # Capture starting position\n",
    "            continue\n",
    "        \n",
    "        # If line break detected OR format changes:\n",
    "        if not is_same_line or word['type'] != current_block['type']:\n",
    "            \n",
    "            # --- END OF CURRENT BLOCK ---\n",
    "            # 1. Process the finished block and append to results list\n",
    "            # We use the captured 'top' coordinate of the *starting* word\n",
    "            result_blocks.append({\n",
    "                'type': 'text',\n",
    "                'top': block_start_top,\n",
    "                'content': process_block(current_block)\n",
    "            })\n",
    "            \n",
    "            # --- START OF NEW BLOCK ---\n",
    "            # 2. Initialize the new block with the current word\n",
    "            current_block = {'type': word['type'], 'words': [word['text']]}\n",
    "            block_start_top = word['top'] # Capture starting position of the new block\n",
    "        \n",
    "        else:\n",
    "            current_block['words'].append(word['text'])\n",
    "            # Same line and same format, append word to current block\n",
    "            # Ensure we maintain x0 positions for sorting when inserting new words\n",
    "            # Initialize parallel _x0s list if not present (attempt to recover x0 for existing words)\n",
    "            # if '_x0s' not in current_block:\n",
    "            #     existing_x0s = []\n",
    "            #     for existing_text in current_block['words']:\n",
    "            #         found_x0 = None\n",
    "            #         # try to find a matching formatted word on the same line to get its x0\n",
    "            #         for fw in formatted_words:\n",
    "            #             if fw['text'] == existing_text and abs(fw['top'] - block_start_top) < 8:\n",
    "            #                 found_x0 = fw.get('x0', 0)\n",
    "            #                 break\n",
    "            #         existing_x0s.append(found_x0 if found_x0 is not None else 0)\n",
    "            #     current_block['_x0s'] = existing_x0s\n",
    "\n",
    "            # # Find insertion index based on word['x0']\n",
    "            # insert_idx = len(current_block['words'])\n",
    "            # for idx, existing_x0 in enumerate(current_block['_x0s']):\n",
    "            #     if word['x0'] < existing_x0:\n",
    "            #         insert_idx = idx\n",
    "            #         break\n",
    "\n",
    "            # Insert text and corresponding x0 at the computed position\n",
    "            # current_block['words'].insert(insert_idx, word['text'])\n",
    "            # current_block['_x0s'].insert(insert_idx, word['x0'])\n",
    "    \n",
    "    # Process the very last block after the loop ends\n",
    "    if current_block:                   \n",
    "        result_blocks.append({\n",
    "            'type': 'text',\n",
    "            'top': block_start_top,\n",
    "            'content': process_block(current_block)\n",
    "        })\n",
    "        \n",
    "    return result_blocks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44905ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./sample/gt/Public_257.pdf with 21 pages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Conversion successful! Output saved at: ./sample/pred/Public_257.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/2nvkbs5d7_7cgdwwkbwy72tm0000gn/T/ipykernel_29091/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUTION ---\n",
    "pdf_path = \"./sample/gt/Public_257.pdf\" \n",
    "output_path = pdf_path.replace('.pdf', '.md').replace(\"gt\",\"pred\")\n",
    "\n",
    "markdown_content = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    print(f\"Processing file: {pdf_path} with {len(pdf.pages)} pages...\")\n",
    "    \n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        # if i != 8:\n",
    "        #     continue\n",
    "        \n",
    "        # --- Step 1: Extract Tables and Text Lines ---\n",
    "        tables = page.find_tables()\n",
    "        table_bboxes = [t.bbox for t in tables]\n",
    "        \n",
    "        text_lines = page.extract_text_lines(T_y_tolerance=3)\n",
    "        \n",
    "        # --- Step 2: Filter Text and Prepare Content Blocks ---\n",
    "        \n",
    "        # List to hold all content objects (Text or Table) with their position\n",
    "        content_blocks = []\n",
    "        \n",
    "        # a. Prepare Table Blocks\n",
    "        for table in tables:\n",
    "            content_blocks.append({\n",
    "                'type': 'table',\n",
    "                'top': table.bbox[1], \n",
    "                'content': pdfplumber_table_to_markdown(table)\n",
    "            })\n",
    "\n",
    "        # b. Filter and Group Text Lines\n",
    "        # The text processing is complex:\n",
    "        # 1. We must process 'words' to get formatting information.\n",
    "        # 2. We must use 'text_lines' to get accurate positioning for filtering.\n",
    "        \n",
    "        # Extract all formatted words on the page\n",
    "        all_formatted_words = []\n",
    "        words = page.extract_words()\n",
    "        chars = page.chars\n",
    "        \n",
    "        for word in words:\n",
    "            # Get font name (assume one font per word)\n",
    "            word_chars = [c for c in chars if c['x0'] >= word['x0'] and c['x1'] <= word['x1'] and c['top'] >= word['top'] and c['bottom'] <= word['bottom']]\n",
    "            \n",
    "            font_name = word_chars[0]['fontname'] if word_chars else 'none'\n",
    "            \n",
    "            # Store as a list of word objects\n",
    "            all_formatted_words.append({\n",
    "                'text': word['text'],\n",
    "                'type': get_word_format_type(font_name),\n",
    "                'top': word['top'], \n",
    "                'bottom': word['bottom'],\n",
    "                'x0': word['x0'],\n",
    "                'x1': word['x1']\n",
    "            })\n",
    "\n",
    "        # c. Group and Filter Formatted Words into Text Blocks\n",
    "        text_blocks_to_merge = []\n",
    "        \n",
    "        # Group words into lines based on Y coordinate\n",
    "        current_line_words = []\n",
    "        last_bottom = 0\n",
    "        \n",
    "        # Sort words primarily by 'top' (Y-axis) and secondarily by 'x0' (X-axis)\n",
    "        all_formatted_words.sort(key=lambda w: (w['top'], w['x0']))\n",
    "        \n",
    "        for word in all_formatted_words:\n",
    "            # Check for line break (if current word's top is significantly different from the last word's bottom)\n",
    "            if current_line_words and (word['top'] > last_bottom + 7): \n",
    "                # Process the previous line\n",
    "                if not current_line_words: continue\n",
    "\n",
    "                # Check if this line overlaps with any table (using the whole line's bbox)\n",
    "                line_top = min(w['top'] for w in current_line_words)\n",
    "                line_bottom = max(w['bottom'] for w in current_line_words)\n",
    "                line_x0 = min(w['x0'] for w in current_line_words)\n",
    "                line_x1 = max(w['x1'] for w in current_line_words)\n",
    "                \n",
    "                line_bbox = (line_x0, line_top, line_x1, line_bottom)\n",
    "                \n",
    "                # Apply table filtering logic\n",
    "                is_external_text = get_block_type_and_filter({'top': line_top, 'bottom': line_bottom}, table_bboxes)\n",
    "\n",
    "                if is_external_text is not None:\n",
    "                    text_blocks_to_merge.extend(current_line_words)\n",
    "                    text_blocks_to_merge.append({'text': '\\n', 'type': 'line_break', 'top': line_bottom, 'bottom': line_bottom, 'x0': 0, 'x1': 0})\n",
    "\n",
    "                current_line_words = []\n",
    "            \n",
    "            current_line_words.append(word)\n",
    "            last_bottom = word['bottom']\n",
    "\n",
    "        # Process the last line\n",
    "        if current_line_words:\n",
    "            line_top = min(w['top'] for w in current_line_words)\n",
    "            line_bottom = max(w['bottom'] for w in current_line_words)\n",
    "            \n",
    "            is_external_text = get_block_type_and_filter({'top': line_top, 'bottom': line_bottom}, table_bboxes)\n",
    "\n",
    "            if is_external_text is not None:\n",
    "                text_blocks_to_merge.extend(current_line_words)\n",
    "        \n",
    "        # 4. Merge Formatted Blocks and Prepare for Stitching\n",
    "        # The merge_formatted_blocks function implicitly handles line breaks and formatting\n",
    "        text_blocks = merge_formatted_blocks(i, text_blocks_to_merge)\n",
    "        content_blocks.extend(text_blocks)\n",
    "    \n",
    "\n",
    "        # --- Step 5: Stitch Content Blocks by Position ---\n",
    "        \n",
    "        # Sort all content (Text and Table) based on 'top' coordinate (Y-axis)\n",
    "        content_blocks.sort(key=lambda x: x['top'])\n",
    "        if content_blocks[0]['type'] == 'table' and \"VIETTEL AI RACE\" in content_blocks[0]['content']:\n",
    "            content_blocks = content_blocks[1:]\n",
    "        # if i==4:\n",
    "        #     import ipdb; ipdb.set_trace()   \n",
    "        # Append to final output\n",
    "        page_markdown = [block['content'] for block in content_blocks]\n",
    "        \n",
    "        # markdown_content.append(f\"## Page {i + 1}\\n\")\n",
    "        markdown_content.extend(page_markdown)\n",
    "        # if i == 2:\n",
    "        #     break\n",
    "markdown_content = \"\\n\\n\".join(markdown_content)\n",
    "markdown_content = markdown_content.replace(\"\\n- \", \"\\n\\- \")\n",
    "markdown_content = markdown_content.replace(\"\\n+ \", \"\\n\\+ \")\n",
    "\n",
    "filename = pdf_path.split('/')[-1].split('.pdf')[0]\n",
    "markdown_content = \"# \" + filename+\"\\n\\n\" + markdown_content\n",
    "markdown_content = markdown_content.replace(\"foo\", \"\")\n",
    "\n",
    "# markdown_content = re.sub(r'\\s\\n.', ' ', markdown_content)\n",
    "# markdown_content = markdown_content.replace(' \\n', ' ')\n",
    "# Write result to file\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(markdown_content)\n",
    "    \n",
    "print(f\"\\n✅ Conversion successful! Output saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfba73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "tables_camelot = camelot.read_pdf(\n",
    "            pdf_path, \n",
    "            pages='9', \n",
    "            flavor='lattice', # Dùng 'stream' cho bảng không có đường kẻ, 'lattice' cho bảng có đường kẻ\n",
    "            split_text=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d0b9a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables_camelot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab7ac357",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_plumber = pdf.pages[8].extract_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1554e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_9_267 = pdf.pages[9].to_image(resolution=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97c643be",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_9_267.save(\"page_9_267.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b31fcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tables_plumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f76a9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables_camelot[1].df.replace(r'^\\s*$', np.nan, regex=True).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ffee0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Số TT \\nLoại tiêu \\nKý hiệu \\nTên đầy đủ của t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiêu chuẩn về định dạng thông điệp dữ liệu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Bộ ký tự và \\nmã hóa</td>\n",
       "      <td>ASCII</td>\n",
       "      <td>American Standard Code \\nfor Information \\nInt...</td>\n",
       "      <td>Khuyến nghị áp \\ndụng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                     1  \\\n",
       "0  Số TT \\nLoại tiêu \\nKý hiệu \\nTên đầy đủ của t...                         \n",
       "1         Tiêu chuẩn về định dạng thông điệp dữ liệu                         \n",
       "2                                                 11  Bộ ký tự và \\nmã hóa   \n",
       "\n",
       "       2                                                  3  \\\n",
       "0                                                             \n",
       "1                                                             \n",
       "2  ASCII  American Standard Code \\nfor Information \\nInt...   \n",
       "\n",
       "                       4  \n",
       "0                         \n",
       "1                         \n",
       "2  Khuyến nghị áp \\ndụng  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b2c1b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Bắt buộc áp'], ['dụng']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[4].extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed2de520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'top': 190.73264000000006,\n",
       "  'content': 'c) Thông tin Cổng eSign cung cấp cho các HTTT gồm: sp_id và sp_password hoặc token, trong đó:'},\n",
       " {'type': 'text',\n",
       "  'top': 235.37264000000005,\n",
       "  'content': '- sp_id: Mã xác thực được cấp cho HTTT.'},\n",
       " {'type': 'text',\n",
       "  'top': 260.72264000000007,\n",
       "  'content': '- sp_password: Mật khẩu kết nối được cấp cho HTTT tương ứng với sp_id. - token: Thông tin xác thực được cấp cho HTTT.'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f729bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_eds': 0.19222203045768715, 'text_f1': 0.5985663082437276, 'head_eds': 0.8705501618122977, 'head_teds': 0.8560823820578533, 'seg_kt': np.float64(0.9591836734693877), 'word_kt': np.float64(0.9936321443106559), 'seg_sp': np.float64(0.9716017316017316), 'word_sp': np.float64(0.9930480547205405)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! python3 evaluation/suite_e2e.py --gold_dir sample/gt --pred_dir sample/pred/ --result_json sample/gt.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "var",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
