{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f171042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- 1. FORMATTING & HEADING LOGIC ---\n",
    "\n",
    "def is_bold(font_name):\n",
    "    \"\"\"Checks if the font name contains keywords suggesting 'Bold'.\"\"\"\n",
    "    return 'bold' in font_name.lower() or 'black' in font_name.lower()\n",
    "\n",
    "def is_italic(font_name):\n",
    "    \"\"\"Checks if the font name contains keywords suggesting 'Italic'.\"\"\"\n",
    "    return 'italic' in font_name.lower() or 'oblique' in font_name.lower()\n",
    "\n",
    "def get_word_format_type(font_name):\n",
    "    \"\"\"Determines the format type: 'bold', 'italic', or 'none'.\"\"\"\n",
    "    if is_bold(font_name):\n",
    "        return 'bold'\n",
    "    if is_italic(font_name):\n",
    "        return 'italic'\n",
    "    return 'none'\n",
    "\n",
    "def dataframe_to_custom_html(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Converts a Pandas DataFrame into a highly customized HTML table structure\n",
    "    where every cell is wrapped in <blockquote><p> tags and headers are bolded.\n",
    "    \"\"\"\n",
    "    html_parts = []\n",
    "    \n",
    "    # Start Table\n",
    "    html_parts.append(\"<table>\")\n",
    "\n",
    "    # 1. Generate Colgroup (one <col/> for each column)\n",
    "    html_parts.append(\"<colgroup>\")\n",
    "    for _ in df.columns:\n",
    "        html_parts.append(\"<col/>\")\n",
    "    html_parts.append(\"</colgroup>\")\n",
    "\n",
    "    # 2. Generate Table Header (<thead>)\n",
    "    html_parts.append(\"<thead>\")\n",
    "    html_parts.append(\"<tr>\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Header cell requires <blockquote><p><strong>...</strong></p></blockquote>\n",
    "        header_content = f\"<blockquote><p><strong>{col}</strong></p></blockquote>\"\n",
    "        html_parts.append(f\"<th>{header_content}</th>\")\n",
    "        \n",
    "    html_parts.append(\"</tr>\")\n",
    "    html_parts.append(\"</thead>\")\n",
    "\n",
    "    # 3. Generate Table Body (<tbody>)\n",
    "    html_parts.append(\"<tbody>\")\n",
    "    \n",
    "    # Iterate through rows\n",
    "    for _, row in df.iterrows():\n",
    "        html_parts.append(\"<tr>\")\n",
    "        \n",
    "        # Iterate through cells in the row\n",
    "        for cell_value in row:\n",
    "            # Data cell requires <blockquote><p>...</p></blockquote>\n",
    "            # Convert cell value to string to handle mixed types\n",
    "            cell_str = str(cell_value)\n",
    "            data_content = f\"<blockquote><p>{cell_str}</p></blockquote>\"\n",
    "            html_parts.append(f\"<td>{data_content}</td>\")\n",
    "            \n",
    "        html_parts.append(\"</tr>\")\n",
    "        \n",
    "    html_parts.append(\"</tbody>\")\n",
    "    \n",
    "    # End Table\n",
    "    html_parts.append(\"</table>\")\n",
    "    \n",
    "    return \"\\n\".join(html_parts)\n",
    "\n",
    "def process_block(block):\n",
    "    \"\"\"\n",
    "    Wraps a text block with appropriate Markdown syntax.\n",
    "    \n",
    "    If the block is bold and starts with a numbered list (e.g., \"1. \"), \n",
    "    it is treated as a special [DIGITAL] heading, and the numbering is removed.\n",
    "    \"\"\"\n",
    "    # Join words into a single string\n",
    "    text = \" \".join(block['words'])\n",
    "    \n",
    "    # Regex pattern: start of string (^), one or more digits (\\d+), dot (\\.), space (\\s)\n",
    "    ordered_list_pattern = re.compile(r\"^\\d+\\.\\s\")\n",
    "    ordered_sublist_pattern = re.compile(r\"^\\d+\\.\\d+\")\n",
    "    ordered_subsublist_pattern = re.compile(r\"^\\d+\\.\\d+\\.\\d+\")\n",
    "\n",
    "\n",
    "    \n",
    "    # 1. Check for [DIGITAL] Heading (Highest Priority)\n",
    "    if block['type'] == 'bold' and ordered_subsublist_pattern.match(text):\n",
    "        return \"### \" + text\n",
    "    if block['type'] == 'bold' and ordered_sublist_pattern.match(text):\n",
    "        # Remove the numbering part (e.g., \"1.1. \")\n",
    "        # cleaned_text = re.sub(ordered_sublist_pattern, \"## \", text, count=1)\n",
    "        # Apply the [DIGITAL] prefix\n",
    "        return \"## \"+ text\n",
    "    elif block['type'] == 'bold' and ordered_list_pattern.match(text):\n",
    "        # Remove the numbering part (e.g., \"1. \")\n",
    "        # cleaned_text = re.sub(ordered_list_pattern, \"# \", text, count=1)\n",
    "        # Apply the [DIGITAL] prefix\n",
    "        return \"# \" + text\n",
    "        \n",
    "    # 2. Regular Bold Formatting\n",
    "    elif block['type'] == 'bold':\n",
    "        return f\"**{text}** \"\n",
    "        \n",
    "    # 3. Italic Formatting\n",
    "    elif block['type'] == 'italic':\n",
    "        return f\"_{text}_ \"\n",
    "        \n",
    "    # 4. No Formatting\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# --- 2. TABLE PROCESSING LOGIC ---\n",
    "\n",
    "def pdfplumber_table_to_markdown(table):\n",
    "    \"\"\"Converts a pdfplumber Table object to a Markdown string.\"\"\"\n",
    "    \n",
    "    data = table.extract()\n",
    "    if not data or not data[0]:\n",
    "        return \"\"\n",
    "    \n",
    "    # Use Pandas for clean conversion to Markdown table syntax\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    # Fill None/NaN with empty strings for clean Markdown rendering\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('') \n",
    "\n",
    "    if len(df) > 1:\n",
    "        header = df.iloc[0].astype(str).fillna('')\n",
    "        df_no_header = df[1:].copy().reset_index(drop=True)\n",
    "        df_no_header.columns = header\n",
    "    else:\n",
    "        # Nếu chỉ có một hàng (chỉ header), tạo DataFrame rỗng với header đó\n",
    "        header = df.iloc[0].astype(str).fillna('') if len(df) == 1 else []\n",
    "        df_no_header = pd.DataFrame(columns=header)\n",
    "    html_table = dataframe_to_custom_html(df_no_header)\n",
    "    # markdown_output = df_no_header.to_markdown(index=False)\n",
    "    # Add extra lines for separation\n",
    "    return \"\\n\" + html_table + \"\\n\\n\"\n",
    "\n",
    "# --- 3. CORE STITCHING LOGIC ---\n",
    "\n",
    "def get_block_type_and_filter(line, table_bboxes):\n",
    "    \"\"\"\n",
    "    Checks if a text line overlaps with any table bbox. \n",
    "    Returns the line object if it's external text, otherwise returns None (filtered out).\n",
    "    \"\"\"\n",
    "    # Get Y coordinates of the text line\n",
    "    line_y_top = line['top']\n",
    "    line_y_bottom = line['bottom']\n",
    "    \n",
    "    for t_x0, t_top, t_x1, t_bottom in table_bboxes:\n",
    "        # Check for overlap in the Y-axis\n",
    "        # If the line is fully contained within the table's Y range, filter it out.\n",
    "        if t_top <= line_y_top < t_bottom and t_top < line_y_bottom <= t_bottom:\n",
    "             return None # It's part of a table, discard the text line\n",
    "    \n",
    "    # If it passed the filter, return the line object\n",
    "    return line\n",
    "\n",
    "def merge_formatted_blocks(page_id, formatted_words):\n",
    "    \"\"\"\n",
    "    Merges consecutive words with the same formatting into a list of structured \n",
    "    content blocks, suitable for positional stitching.\n",
    "    \"\"\"\n",
    "    if not formatted_words:\n",
    "        return []\n",
    "    \n",
    "    # This list will hold the final dictionary blocks\n",
    "    result_blocks = []\n",
    "    current_block = None\n",
    "    block_start_top = None # To track the 'top' coordinate of the starting word\n",
    "    \n",
    "    # Ensure words are sorted by position before merging (Top then X-axis)\n",
    "    # The calling function (pdf_to_markdown_pipeline) usually does this, \n",
    "    # but it's good practice to ensure here as well.\n",
    "    new_words = []\n",
    "    for word in formatted_words:\n",
    "        if word['text'] == \"\\n\":\n",
    "            continue\n",
    "        new_words.append(word)\n",
    "    formatted_words = new_words\n",
    "    formatted_words.sort(key=lambda w: (w['top'], w['x0']))\n",
    "\n",
    "\n",
    "\n",
    "    list_words = [w['text'] for w in formatted_words]\n",
    "    # if page_id == 4:\n",
    "    #     import ipdb; ipdb.set_trace()\n",
    "    for i, word in enumerate(formatted_words):\n",
    "        # Check if this word is on the same line as the previous word (Y coordinate check)\n",
    "        is_same_line = False\n",
    "        \n",
    "        if i > 0:\n",
    "            if abs(word['top'] - formatted_words[i-1]['top']) < 7:\n",
    "                is_same_line = True\n",
    "            elif formatted_words[i-1]['x1'] > 507 and not word['text'][0].isupper():\n",
    "                # Special case: if previous word is at the far right and current word starts with lowercase,\n",
    "                # consider it as same line (likely a line continuation)\n",
    "                is_same_line = True\n",
    "                # if page_id == 2:\n",
    "                    # print(\"Special line continuation detected:\", formatted_words[i-1]['text'], \"->\", word['text'])\n",
    "                    # print(formatted_words[i-1], word, formatted_words[i+1])\n",
    "        \n",
    "                \n",
    "        if current_block is None:\n",
    "            # Start the very first block\n",
    "            current_block = {'type': word['type'], 'words': [word['text']]}\n",
    "            block_start_top = word['top'] # Capture starting position\n",
    "            continue\n",
    "        \n",
    "        # If line break detected OR format changes:\n",
    "        if not is_same_line or word['type'] != current_block['type']:\n",
    "            \n",
    "            # --- END OF CURRENT BLOCK ---\n",
    "            # 1. Process the finished block and append to results list\n",
    "            # We use the captured 'top' coordinate of the *starting* word\n",
    "            result_blocks.append({\n",
    "                'type': 'text',\n",
    "                'top': block_start_top,\n",
    "                'content': process_block(current_block)\n",
    "            })\n",
    "            \n",
    "            # --- START OF NEW BLOCK ---\n",
    "            # 2. Initialize the new block with the current word\n",
    "            current_block = {'type': word['type'], 'words': [word['text']]}\n",
    "            block_start_top = word['top'] # Capture starting position of the new block\n",
    "        \n",
    "        else:\n",
    "            current_block['words'].append(word['text'])\n",
    "            # Same line and same format, append word to current block\n",
    "            # Ensure we maintain x0 positions for sorting when inserting new words\n",
    "            # Initialize parallel _x0s list if not present (attempt to recover x0 for existing words)\n",
    "            # if '_x0s' not in current_block:\n",
    "            #     existing_x0s = []\n",
    "            #     for existing_text in current_block['words']:\n",
    "            #         found_x0 = None\n",
    "            #         # try to find a matching formatted word on the same line to get its x0\n",
    "            #         for fw in formatted_words:\n",
    "            #             if fw['text'] == existing_text and abs(fw['top'] - block_start_top) < 8:\n",
    "            #                 found_x0 = fw.get('x0', 0)\n",
    "            #                 break\n",
    "            #         existing_x0s.append(found_x0 if found_x0 is not None else 0)\n",
    "            #     current_block['_x0s'] = existing_x0s\n",
    "\n",
    "            # # Find insertion index based on word['x0']\n",
    "            # insert_idx = len(current_block['words'])\n",
    "            # for idx, existing_x0 in enumerate(current_block['_x0s']):\n",
    "            #     if word['x0'] < existing_x0:\n",
    "            #         insert_idx = idx\n",
    "            #         break\n",
    "\n",
    "            # Insert text and corresponding x0 at the computed position\n",
    "            # current_block['words'].insert(insert_idx, word['text'])\n",
    "            # current_block['_x0s'].insert(insert_idx, word['x0'])\n",
    "    \n",
    "    # Process the very last block after the loop ends\n",
    "    if current_block:                   \n",
    "        result_blocks.append({\n",
    "            'type': 'text',\n",
    "            'top': block_start_top,\n",
    "            'content': process_block(current_block)\n",
    "        })\n",
    "        \n",
    "    return result_blocks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c877bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "model_name = '../Deepseek_OCR'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, _attn_implementation='flash_attention_2', trust_remote_code=True, use_safetensors=True)\n",
    "model = model.eval().cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fe034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def treat_page_with_llm(page):\n",
    "    page_image = page.to_image(resolution=300)\n",
    "    # Load and do a quick pass over \"sample/result.mmd\" for further processing\n",
    "    result_mmd_path = \"sample/result.mmd\"\n",
    "\n",
    "    prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "    image_file =\"temp.png\"\n",
    "    page_image.save(image_file)\n",
    "    output_path = \"temp_result\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, \n",
    "                      base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)\n",
    "\n",
    "\n",
    "\n",
    "    # Read file\n",
    "    with open(os.path.join(output_path, \"result.mmd\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        result_mmd = f.read()\n",
    "\n",
    "    # Basic derived variables for downstream cells\n",
    "    result_mmd_lines = result_mmd.splitlines()\n",
    "    result_mmd_blocks = result_mmd.split(\"\\n\\n\")\n",
    "\n",
    "    # Find referenced image placeholders like <image_1>\n",
    "    image_refs = re.findall(r\"<image_(\\d+)>\", result_mmd)\n",
    "    image_refs = sorted(set(image_refs), key=lambda s: int(s))\n",
    "\n",
    "    table_refs = re.findall(r\"<table>\", result_mmd)\n",
    "\n",
    "    fintune_blocks = []\n",
    "    for block in result_mmd_blocks:\n",
    "        if \"<table>\" in block and \"VIETTEL AI RACE\" in block:\n",
    "            continue\n",
    "        if \"<table>\" in block:\n",
    "            # Replace with processed table markdown\n",
    "            block = block.replace(\"<td>\", \"<td><em>\")\n",
    "            block = block.replace(\"<tr>\", \"<tr>\\n\")\n",
    "            block = block.replace(\"<table>\", \"<table>\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            block = block.replace(\"</td>\", \"</em></td>\\n\")\n",
    "        fintune_blocks.append(block)\n",
    "    mkdown = \"\\n\\n\".join(fintune_blocks)\n",
    "    return mkdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44905ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./sample/gt/Public_257.pdf with 21 pages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 8 area table 0.5457161775398249 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[139, 60, 875, 199]]<|/det|>\n",
      "<table><tr><td>VIETTELAI RACE</td><td>Public 257</td></tr><tr><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>sub_title<|/ref|><|det|>[[471, 223, 574, 244]]<|/det|>\n",
      "## Phụ lục I \n",
      "\n",
      "<|ref|>sub_title<|/ref|><|det|>[[161, 250, 884, 319]]<|/det|>\n",
      "### DANH MỤC TIÊU CHUẨN KỸ THUẬT VỀ CHỮ KÝ SỐ TRÊN THÔNG ĐIỆP DỮ LIỆU DÙNG CHO PHẦN MỀM KÝ SỐ VÀ PHẦN MỀM KIỂM TRA CHỮ KÝ SỐ \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[197, 327, 901, 368]]<|/det|>\n",
      "(Ban hành kèm theo Thông tư số /2025/TT-BKHCN ngày tháng năm 2025 của Bộ trưởng Bộ Khoa học và Công nghệ) \n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[139, 373, 904, 894]]<|/det|>\n",
      "<table><tr><td>Số TT</td><td>Loại tiêu chuẩn</td><td>Ký hiệu tiêu chuẩn</td><td>Tên đầy đủ của tiêu chuẩn</td><td>Quy định áp dụng</td></tr><tr><td colspan=\"5\">Tiêu chuẩn về định dạng thông điệp dữ liệu</td></tr><tr><td>11</td><td>Bộ ký tự và mã hóa</td><td>ASCII</td><td>American Standard Code for Information Interchange</td><td>Khuyến nghị áp dụng</td></tr><tr><td>12</td><td>Bộ ký tự và mã hóa cho tiếng Việt</td><td>TCVN 6909:2001</td><td>TCVN 6909:2001 \" Công nghệ thông tin-Bộ mã ký tự tiếng Việt 16-bit\"</td><td>Bắt buộc áp dụng</td></tr><tr><td>13</td><td>Trình diễn bộ ký tự</td><td>UTF-8</td><td>8-bit Universal Character Set (UCS)/ Unicode Transformation Format</td><td>Khuyến nghị áp dụng</td></tr><tr><td>14</td><td>Ngôn ngữ định dạng thông điệp dữ liệu</td><td>XML v1.0 (5th Edition)<br/>XML v1.1 (2nd Edition)</td><td>Extensible Markup Language version 1.0 (5th Edition)<br/>Extensible Markup Language version 1.1</td><td>Khuyến nghị áp dụng một trong hai tiêu chuẩn</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  672\n",
      "compression ratio:  0.86\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 5/5 [00:00<00:00, 108100.62it/s]\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 9 area table 0.720745926719857 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[137, 59, 876, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTEL AI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[137, 220, 904, 626]]<|/det|>\n",
      "<table><tr><td>15</td><td>Định nghĩa các lược đồ trong tài liệu XML</td><td>XML Schema version 1.1</td><td>XML Schema version 1.1</td><td>Khuyến nghị áp dụng</td></tr><tr><td>16</td><td>Trao đổi dữ liệu đặc tả tài liệu XML</td><td>XML v2.4.2</td><td>XML Metadata Interchange version 2.4.2</td><td>Khuyến nghị áp dụng</td></tr><tr><td>77</td><td>Quản lý tài liệu - Định dạng tài liệu di động</td><td>ISO 32000-1:2008</td><td>Document management - Portable document format</td><td>Khuyến nghị áp dụng</td></tr><tr><td>88</td><td>Định dạng trao đổi dữ liệu theo ký hiệu đối tượng Javascript</td><td>RFC7159</td><td>The JavaScript Object Notation (JSON) Data Interchange Format</td><td>Khuyến nghị áp dụng</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[137, 636, 904, 910]]<|/det|>\n",
      "<table><tr><td colspan=\"4\">Tiêu chuẩn về ký số, kiểm tra chữ ký số</td></tr><tr><td>21</td><td colspan=\"3\">Tiêu chuẩn về ký số trên thiết bị quản lý khóa bí mật, phần mềm ký số, tạo chữ ký số, chứng thư số, phần mềm kiểm tra chữ ký số.</td></tr><tr><td rowspan=\"2\">21.1</td><td rowspan=\"2\">Thuật toán mã hóa</td><td>TCVN 7816:2007</td><td>Công nghệ thông tin. Kỹ thuật mật mã - thuật toán mã dữ liệu AES</td><td>Khuyến nghị áp dụng</td></tr><tr><td>NIST 800-67</td><td>Recommendation for the Triple Data Encryption Algorithm (TDEA) Block Cipher</td><td>Khuyến nghị áp dụng</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  591\n",
      "compression ratio:  0.76\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 3/3 [00:00<00:00, 64860.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 10 area table 0.6442953142732624 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[139, 60, 875, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTELAI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[137, 216, 905, 927]]<|/det|>\n",
      "<table><tr><td></td><td></td><td>PKCS#1</td><td>RSA Cryptography Standard (Phiên bản 2.1 trở lên)<br/>Áp dụng, sử dụng lược đồ RSAES-OAEP để mã hoá<br/>Độ dài khóa tối thiểu là 2048 bit</td><td>Khuyến nghị áp dụng</td></tr><tr><td></td><td></td><td>ECC</td><td>Elliptic Curve Crytography</td><td>Khuyến nghị áp dụng</td></tr><tr><td rowspan=\"3\">21.2</td><td rowspan=\"3\">Thuật toán chữ ký số</td><td>TCVN<br/>7635:2007</td><td>Các kỹ thuật mật mã - Chữ ký số</td><td>- Áp dụng một trong ba tiêu chuẩn.<br/>- Đối với tiêu chuẩn TCVN 7635:2007 và PKCS#1:<br/>+ Phiên bản 2.1<br/>+ Áp dụng lược đồ RSAES-OAEP để mã hoá và RSASSA-PSS để ký.<br/>+ Độ dài khóa tối thiểu là 2048 bit<br/>- Đối với tiêu chuẩn ECDSA: độ dài khóa tối thiểu là 256 bit</td></tr><tr><td>PKCS#1</td><td>RSA Cryptography Standard</td><td></td></tr><tr><td>ANSI<br/>X9.62-2005</td><td>Public Key Cryptography for the Financial Services Industry: The Elliptic Curve Digital Signature Algorithm (ECDSA)</td><td></td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  488\n",
      "compression ratio:  0.62\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 2/2 [00:00<00:00, 52758.54it/s]\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 11 area table 0.7391190364361847 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[137, 60, 875, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTELAI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[137, 220, 904, 932]]<|/det|>\n",
      "<table><tr><td rowspan=\"2\">21.3</td><td rowspan=\"2\">Hàm băm an toàn</td><td>FIPS PUB 180-4</td><td>Secure Hash Algorithms</td><td rowspan=\"2\">Áp dụng một trong các hàm băm sau:<br/>SHA-224,<br/>SHA-256,<br/>SHA-384,<br/>SHA-512,<br/>SHA-512/224,<br/>SHA-512/256,<br/>SHA3-224,<br/>SHA3-256,<br/>SHA3-384,<br/>SHA3-512,<br/>SHAKE128,<br/>SHAKE256</td></tr><tr><td>FIPS PUB 202</td><td>SHA-3 Standard: Permutation-Based Hash and Extendable-Output Functions</td></tr><tr><td rowspan=\"2\">21.4</td><td rowspan=\"2\">Cú pháp mã hóa và cách xử lý thông điệp dữ liệu định dạng XML</td><td>XML Encryption Syntax and Processing</td><td>XML Encryption Syntax and Processing</td><td>Bắt buộc áp dụng</td></tr><tr><td>XML Signature Syntax and Processing</td><td>XML Signature Syntax and Processing</td><td>Bắt buộc áp dụng</td></tr><tr><td>21.5</td><td>Quản lý khóa công khai thông điệp dữ liệu định dạng XML</td><td>XKMS v2.0</td><td>XML Key Management Specification version 2.0</td><td>Bắt buộc áp dụng</td></tr><tr><td>21.6</td><td>Cú pháp thông điệp</td><td>PKCS#7 v1.5 (RFC 2315)</td><td>Cryptographic message syntax for file-based</td><td>Bắt buộc áp dụng</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  526\n",
      "compression ratio:  0.67\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 2/2 [00:00<00:00, 49056.19it/s]\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 12 area table 0.7472878742312463 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[139, 59, 875, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTEL AI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[139, 220, 904, 921]]<|/det|>\n",
      "<table><tr><td></td><td>mật mã cho ký, mã hóa</td><td></td><td>signing and encrypting version 1.5</td><td></td></tr><tr><td>11.7</td><td>Tiêu chuẩn về chữ ký điện tử nâng cao dành cho thông điệp dữ liệu định dạng PDF</td><td>ETSI EN 319 142-1</td><td>Electronic Signatures and Infrastructures (ESI) - PAEDS digital signatures</td><td>Áp dụng một trong hai tiêu chuẩn PAEDS hoặc CAEDS</td></tr><tr><td>11.8</td><td>Tiêu chuẩn về chữ ký điện tử nâng cao dành chо thông điệp dữ liệu định dạng XML</td><td>ETSI TS 101 903</td><td>Electronic Signatures and Infrastructures (ESI) - XML Advanced Electronic Signatures (XAdES)</td><td>Áp dụng một trong hai tiêu chuẩn XAdES hoặc CAEDS</td></tr><tr><td>11.9</td><td>Tiêu chuẩn về chữ ký điện tử nâng cao dành cо thông điệp dữ liệu định dạng JSON</td><td>RFC 7515</td><td>JSON Web Signature (JWS)</td><td>Bắt buộc áp dụng cho thông điệp dữ liệu định dạng JSON</td></tr><tr><td>11.10</td><td>Tiêu chuẩn về chữ ký điện tử nâng cao dành có cú pháp tin nhắn mật mã</td><td>ETSI TS 101 733</td><td>Electronic Signatures and Infrastructures (ESI) - CMS Advanced Electronic Signatures (CAfES)</td><td>Khuyến nghị áp dụng</td></tr><tr><td>.2</td><td colspan=\"4\">Tiêu chuẩn về hệ thống, thiết bị lưu trữ và sử dụng khóa bí mật</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  554\n",
      "compression ratio:  0.71\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 2/2 [00:00<00:00, 49056.19it/s]\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 13 area table 0.7427795640785467 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[139, 58, 875, 200]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTEL AI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[139, 220, 904, 932]]<|/det|>\n",
      "<table><tr><td>22.1</td><td>Yêu cầu an toàn dành cho mô đun bảo mật phần cứng</td><td>FIPS PUB 140-2</td><td>Security Requirements for Cryptographic Modules</td><td>- Yêu cầu tối thiểu mức 3 (level 3)</td></tr><tr><td>22.2</td><td>Yêu cầu an toàn đối với thẻ Token và Smart card</td><td>FIPS PUB 140-2</td><td>Security Requirements for Cryptographic Modules</td><td>-Yêu cầu tối thiểu mức 2 (level 2)</td></tr><tr><td rowspan=\"2\">.2.3</td><td rowspan=\"2\">Yêu cầu về chính sách và an toàn cho các tổ chức cung cấp dịch vụ tin cậy: Các thành phần dịch vụ vận hành thiết bị tạo chữ ký số và hỗ trợ tạo chữ ký số AdES</td><td>ETSI TS 119 431-1</td><td>Electronic Signatures and Infrastructures (ESI); Policy and security requirements for trust service providers; Part 1: TSP service components operating a remote QSCD/SCDev</td><td>Áp dụng cả bộ tiêu chuẩn 2 phần; Phiên bản V1.1.1 (12/2018)</td></tr><tr><td>ETSI TS 119 431-2</td><td>Electronic Signatures and Infrastructures (ESI); Policy and security requirements for trust service proviers; Part 2: TSP service components supporting AdES digital signature creation</td><td></td></tr><tr><td>.2.4</td><td>Giao thức tạo chữ ký số từ xa</td><td>ETSI TS 119 432</td><td>Electronic Signatures and Infrastructures (ESI); Protocols for remote digital signature creation</td><td>Phiên bản V1.1.1 (03/2019)</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  560\n",
      "compression ratio:  0.72\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 2/2 [00:00<00:00, 52758.54it/s]\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 14 area table 0.6703982412163356 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[137, 58, 875, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTEL AI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[137, 220, 904, 925]]<|/det|>\n",
      "<table><tr><td>.2.5</td><td>Hệ thống tin cây hỗ trợ ký số từ xa - Các yêu cầu chung</td><td>EN 419241-1:2018</td><td>Trustworthy Systems Supporting Server Signing - Part 1: General system security requirements</td></tr><tr><td>.2.6</td><td>Hệ thống tin cây hỗ trợ ký số từ xà - Yêu cầu và mục tiêu (hồ sơ bảo vệ) của thiết bị tạo chữ ký số dành cho ký số từ xa</td><td>EN 419241-2:2019</td><td>Trustworthy Systems Supporting Server Signing - Part 2: Protection Profile for QSCD for Server Signing</td></tr><tr><td>.2.7</td><td>Yêu cầu và mục tiêu (hồ sơ bảo vệ) dành cho mô đun bảo mật phần cứng của tổ chức cung cấp dịch vụ tin cậy - mô đun mã hóa dành cho các dịch vụ tin cậy</td><td>EN 419221-5:2018</td><td>Protection Profiles for TSP Cryptographic modules - Part 5: Cryptographic Module for Trust Services</td></tr><tr><td>33</td><td colspan=\"3\">Tiêu chuẩn kiểm tra trạng thái chứng thực số</td></tr><tr><td>33.1</td><td>Giao thức truyền, nhận</td><td>RFC 2585</td><td>Internet X.509 Public Key Infrastructure -</td><td>Áp dụng một hoặc cả hai giao</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  499\n",
      "compression ratio:  0.64\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 2/2 [00:00<00:00, 57065.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 15 area table 0.38195012503214265 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[137, 59, 875, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTELAI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[137, 220, 904, 569]]<|/det|>\n",
      "<table><tr><td></td><td>chứng thực chữ ký số và danh sách chứng thực chữ ký số bị thu hồi</td><td></td><td>Operational Protocols: FTP and HTTP</td><td>thức FTP và HTTP</td></tr><tr><td>33.2</td><td>Giao thức bảo mật tầng giao vận</td><td>RFC 8446</td><td>The Transport Layer Security (TLS) Protocol Version 1.3</td><td>Bắt buộc áp dụng tối thiểu</td></tr><tr><td>33.3</td><td>Giao thức cho kiểm tra trạng thái chứng thực chữ ký số trực tuyến</td><td>RFC 2560</td><td>X.509 Internet Public Key Infrastructure - Online Certificate status protocol</td><td></td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  309\n",
      "compression ratio:  0.4\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 2/2 [00:00<00:00, 60349.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 16 area table 0.5078802729621537 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[139, 60, 875, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTELAI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>sub_title<|/ref|><|det|>[[466, 223, 576, 245]]<|/det|>\n",
      "Phụ lục II \n",
      "\n",
      "<|ref|>sub_title<|/ref|><|det|>[[152, 250, 890, 320]]<|/det|>\n",
      "DANH MỤC TIÊU CHÍ ĐÁNH GIÁ HIỆU LỰC CỦA CHỨNG THỨ CHỨ KÝ SỐ VÀ CHỨ KÝ SỐ HỢP LỆ TRONG PHẦN MỀM KÝ SỐ, PHẦN MỀM KIỂM TRA CHỨ KÝ SỐ \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[200, 327, 900, 369]]<|/det|>\n",
      "(Ban hành kèm theo Thông tư số /2025/TT-BKHCN ngày tháng năm 2025 của Bộ trưởng Bộ Khoa học và Công nghệ) \n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[139, 373, 904, 920]]<|/det|>\n",
      "<table><tr><td>Số TT</td><td>Tiêu chí đánh giá</td><td>Hiệu lực/hợp lệ</td><td>Quy định áp dụng</td></tr><tr><td>1</td><td>Tính hiệu lực của chứng thư chữ ký số</td><td></td><td></td></tr><tr><td>1.1</td><td>Thời gian có hiệu lực của chứng thư số</td><td>Thời gian trên chứng thư chữ ký số còn hiệu lực tại thời điểm ký số</td><td>Bắt buộc áp dụng</td></tr><tr><td>1.2</td><td>Trạng thái chứng thư số qua danh sách chứng thư chữ ký số thu hồi (CRL) được công bố tại thời điểm ký số hoặc bằng phương pháp kiểm tra trạng thái chứng thư chữ ký số trực tuyến (OCSP) ở chế độ trực tuyến trong trường hợp tổ chức cung cấp dịch vụ chứng thực chữ ký số có cung cấp dịch vụ OCSP</td><td>Trạng thái của chứng thư chữ ký số còn hoạt động tại thời điểm ký số</td><td>Bắt buộc áp dụng</td></tr></table><table><tr><td>1.3</td><td>Thuật toán mật mã trên chứng thư chữ ký số</td><td>Các thuật toán mật mã trên chứng thư chữ ký số tuân thủ theo quy định về quy chuẩn, tiêu chuẩn kỹ thuật bắt buộc áp dụng về chữ ký số và dịch vụ chứng thực</td><td>Bắt buộc áp dụng</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  748\n",
      "compression ratio:  0.96\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 5/5 [00:00<00:00, 104857.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 17 area table 0.631584436412993 processing with llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/home/dtw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>table<|/ref|><|det|>[[139, 59, 875, 199]]<|/det|>\n",
      "<table><tr><td></td><td>VIETTEL AI RACE</td><td>Public 257</td></tr><tr><td></td><td>Quy định yêu cầu kỹ thuật đối với phần mềm ký số, phần mềm kiểm tra chữ ký số và Cổng kết nối dịch vụ chứng thực chữ ký số công cộng</td><td>Lần ban hành: 1</td></tr></table>\n",
      "\n",
      "<|ref|>table<|/ref|><|det|>[[139, 220, 905, 930]]<|/det|>\n",
      "<table><tr><td></td><td></td><td>chữ ký số đang có hiệu lực</td><td></td></tr><tr><td>1.4</td><td>Mục đích, phạm vi sử dụng của chứng thư chữ ký số</td><td>Chứng thư chữ ký số được sử dụng đúng mục đích, phạm vi sử dụng</td><td>Bắt buộc áp dụng</td></tr><tr><td>1.5</td><td>Các tuyên bố khác của Tổ chức cung cấp dịch vụ chứng thực chữ ký số</td><td>Các tuyên bố khác không nằm ngoài phạm vi Quy chế chứng thực của Tổ chức cung cấp dịch vụ chứng thực chứ ký số</td><td>Khuyến nghị áp dụng</td></tr><tr><td>2</td><td colspan=\"3\">Tính hợp lệ của chữ ký số</td></tr><tr><td>2.1</td><td>Thông tin về chủ thể ký</td><td>Kiểm tra, xác thực được đúng thông tin chủ thể ký số</td><td>Bắt buộc áp dụng</td></tr><tr><td>2.2</td><td>Cách thức tạo chữ ký số</td><td>Chữ ký số được tạo ra đúng bởi khóa bí mật tương ứng với khóa công khai trên chứng thư chữ ký số</td><td>Bắt buộc áp dụng</td></tr><tr><td>2.3</td><td>Chứng thư chữ ký số kèm theo thông điệp dữ liệu</td><td>Chứng thư chữ ký số có hiệu lực tại thời điểm ký</td><td>Bắt buộc áp dụng</td></tr><tr><td>2.4</td><td>Tính toàn vẹn của thông điệp dữ liệu</td><td>Mã băm có được từ việc băm thông điệp dữ liệu và mã băm có được khi giải mã chữ ký số trùng nhau</td><td>Bắt buộc áp dụng</td></tr></table>\n",
      "==================================================\n",
      "image size:  (2481, 3509)\n",
      "valid image tokens:  781\n",
      "output texts tokens (valid):  617\n",
      "compression ratio:  0.79\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 2/2 [00:00<00:00, 55553.70it/s]\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Conversion successful! Output saved at: ./sample/pred/Public_257.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n",
      "/tmp/ipykernel_1585096/2978192361.py:134: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('')\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUTION ---\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "pdf_path = \"./sample/gt/Public_257.pdf\" \n",
    "output_path = pdf_path.replace('.pdf', '.md').replace(\"gt\",\"pred\")\n",
    "folder_image = output_path.replace('.md','') + \"/images\"\n",
    "os.makedirs(folder_image, exist_ok=True)\n",
    "markdown_content = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    print(f\"Processing file: {pdf_path} with {len(pdf.pages)} pages...\")\n",
    "    id_image = 1\n",
    "    \n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        images_block = []\n",
    "\n",
    "        # if i != 15:\n",
    "        #     continue\n",
    "\n",
    "        # extract image\n",
    "        imgs = page.images\n",
    "        for id_img, img in enumerate(imgs):\n",
    "            if img['top'] < 70:\n",
    "                continue\n",
    "            content = f\"|<image_{id_image}>|\"\n",
    "            \n",
    "            raw = img[\"stream\"].get_data()\n",
    "            # open with Pillow to decode\n",
    "            try:\n",
    "                image = Image.open(io.BytesIO(raw))\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening image {id_image} on page {i+1}: {e}\")\n",
    "                continue\n",
    "            images_block.append({\n",
    "                'type': 'image',\n",
    "                'top': img['top'],\n",
    "                'content': content\n",
    "            })\n",
    "\n",
    "            # choose filename\n",
    "            filename = f\"{folder_image}/image_{id_image}.png\"\n",
    "            \n",
    "\n",
    "            image.save(filename)\n",
    "\n",
    "            id_image += 1\n",
    "\n",
    "        area_table = 0\n",
    "        area_page = page.width * page.height\n",
    "        \n",
    "        # --- Step 1: Extract Tables and Text Lines ---\n",
    "        tables = page.find_tables()\n",
    "        table_bboxes = [t.bbox for t in tables]\n",
    "        \n",
    "        text_lines = page.extract_text_lines(T_y_tolerance=3)\n",
    "        \n",
    "        # --- Step 2: Filter Text and Prepare Content Blocks ---\n",
    "        \n",
    "        # List to hold all content objects (Text or Table) with their position\n",
    "        content_blocks = []\n",
    "        \n",
    "        # a. Prepare Table Blocks\n",
    "        for table in tables:\n",
    "            content_blocks.append({\n",
    "                'type': 'table',\n",
    "                'top': table.bbox[1], \n",
    "                'content': pdfplumber_table_to_markdown(table)\n",
    "            })\n",
    "            bbox = table.bbox\n",
    "            width = bbox[2] - bbox[0]\n",
    "            height = bbox[3] - bbox[1]\n",
    "            area_table += (width*height)\n",
    "        if area_table/area_page > 0.38:\n",
    "            print(\"page\", i, \"area table\", area_table/area_page, \"processing with llm\")\n",
    "\n",
    "            page_content = treat_page_with_llm(page)\n",
    "            markdown_content.append(page_content)\n",
    "            continue\n",
    "        # b. Filter and Group Text Lines\n",
    "        # The text processing is complex:\n",
    "        # 1. We must process 'words' to get formatting information.\n",
    "        # 2. We must use 'text_lines' to get accurate positioning for filtering.\n",
    "        \n",
    "        # Extract all formatted words on the page\n",
    "        all_formatted_words = []\n",
    "        words = page.extract_words()\n",
    "        chars = page.chars\n",
    "        \n",
    "        for word in words:\n",
    "            # Get font name (assume one font per word)\n",
    "            word_chars = [c for c in chars if c['x0'] >= word['x0'] and c['x1'] <= word['x1'] and c['top'] >= word['top'] and c['bottom'] <= word['bottom']]\n",
    "            \n",
    "            font_name = word_chars[0]['fontname'] if word_chars else 'none'\n",
    "            \n",
    "            # Store as a list of word objects\n",
    "            all_formatted_words.append({\n",
    "                'text': word['text'],\n",
    "                'type': get_word_format_type(font_name),\n",
    "                'top': word['top'], \n",
    "                'bottom': word['bottom'],\n",
    "                'x0': word['x0'],\n",
    "                'x1': word['x1']\n",
    "            })\n",
    "\n",
    "        # c. Group and Filter Formatted Words into Text Blocks\n",
    "        text_blocks_to_merge = []\n",
    "        \n",
    "        # Group words into lines based on Y coordinate\n",
    "        current_line_words = []\n",
    "        last_bottom = 0\n",
    "        \n",
    "        # Sort words primarily by 'top' (Y-axis) and secondarily by 'x0' (X-axis)\n",
    "        all_formatted_words.sort(key=lambda w: (w['top'], w['x0']))\n",
    "        \n",
    "        for word in all_formatted_words:\n",
    "            # Check for line break (if current word's top is significantly different from the last word's bottom)\n",
    "            if current_line_words and (word['top'] > last_bottom + 7): \n",
    "                # Process the previous line\n",
    "                if not current_line_words: continue\n",
    "\n",
    "                # Check if this line overlaps with any table (using the whole line's bbox)\n",
    "                line_top = min(w['top'] for w in current_line_words)\n",
    "                line_bottom = max(w['bottom'] for w in current_line_words)\n",
    "                line_x0 = min(w['x0'] for w in current_line_words)\n",
    "                line_x1 = max(w['x1'] for w in current_line_words)\n",
    "                \n",
    "                line_bbox = (line_x0, line_top, line_x1, line_bottom)\n",
    "                \n",
    "                # Apply table filtering logic\n",
    "                is_external_text = get_block_type_and_filter({'top': line_top, 'bottom': line_bottom}, table_bboxes)\n",
    "\n",
    "                if is_external_text is not None:\n",
    "                    text_blocks_to_merge.extend(current_line_words)\n",
    "                    text_blocks_to_merge.append({'text': '\\n', 'type': 'line_break', 'top': line_bottom, 'bottom': line_bottom, 'x0': 0, 'x1': 0})\n",
    "\n",
    "                current_line_words = []\n",
    "            \n",
    "            current_line_words.append(word)\n",
    "            last_bottom = word['bottom']\n",
    "\n",
    "        # Process the last line\n",
    "        if current_line_words:\n",
    "            line_top = min(w['top'] for w in current_line_words)\n",
    "            line_bottom = max(w['bottom'] for w in current_line_words)\n",
    "            \n",
    "            is_external_text = get_block_type_and_filter({'top': line_top, 'bottom': line_bottom}, table_bboxes)\n",
    "\n",
    "            if is_external_text is not None:\n",
    "                text_blocks_to_merge.extend(current_line_words)\n",
    "        \n",
    "        # 4. Merge Formatted Blocks and Prepare for Stitching\n",
    "        # The merge_formatted_blocks function implicitly handles line breaks and formatting\n",
    "        text_blocks = merge_formatted_blocks(i, text_blocks_to_merge)\n",
    "        content_blocks.extend(text_blocks)\n",
    "        content_blocks.extend(images_block)\n",
    "\n",
    "        # --- Step 5: Stitch Content Blocks by Position ---\n",
    "        \n",
    "        # Sort all content (Text and Table) based on 'top' coordinate (Y-axis)\n",
    "        content_blocks.sort(key=lambda x: x['top'])\n",
    "        if content_blocks[0]['type'] == 'table' and \"VIETTEL AI RACE\" in content_blocks[0]['content']:\n",
    "            content_blocks = content_blocks[1:]\n",
    "        # if i==4:\n",
    "        #     import ipdb; ipdb.set_trace()   \n",
    "        # Append to final output\n",
    "        page_markdown = [block['content'] for block in content_blocks]\n",
    "        \n",
    "        # markdown_content.append(f\"## Page {i + 1}\\n\")\n",
    "        markdown_content.extend(page_markdown)\n",
    "        # if i == 2:\n",
    "        #     break\n",
    "markdown_content = \"\\n\\n\".join(markdown_content)\n",
    "markdown_content = markdown_content.replace(\"\\n- \", \"\\n\\- \")\n",
    "markdown_content = markdown_content.replace(\"\\n+ \", \"\\n\\+ \")\n",
    "\n",
    "filename = pdf_path.split('/')[-1].split('.pdf')[0]\n",
    "markdown_content = \"# \" + filename+\"\\n\\n\" + markdown_content\n",
    "markdown_content = markdown_content.replace(\"foo\", \"\")\n",
    "\n",
    "# markdown_content = re.sub(r'\\s\\n.', ' ', markdown_content)\n",
    "# markdown_content = markdown_content.replace(' \\n', ' ')\n",
    "# Write result to file\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(markdown_content)\n",
    "    \n",
    "print(f\"\\n✅ Conversion successful! Output saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a02c2db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38195012503214265"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_table/area_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f729bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final averaged results: {'text_eds': 0.8572291296625222, 'text_f1': 0.8806500761808024, 'head_eds': 0.7097625329815304, 'head_teds': 0.7704741438520679, 'seg_kt': np.float64(0.9605901766647253), 'word_kt': np.float64(0.9923672464289011), 'seg_sp': np.float64(0.9738876229142046), 'word_sp': np.float64(0.9917006611608322)}\n",
      "top 5 lowest edit distance scores:\n",
      "Public_257.md: 0.8572291296625222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! python3 evaluation/suite_e2e.py --gold_dir sample/gt --pred_dir sample/pred/ --result_json sample/gt.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "var",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
